# Mini-LLM
This project is about building a Mini-LLM that uses a hybrid model combining n-gram and LSTM, and is trained on approximately 100k samples of Persian Wikipedia data.
